{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qhQaMUWNVpbW"
      },
      "outputs": [],
      "source": [
        "# Load pretrained word2vec embeddings\n",
        "from gensim.models import KeyedVectors\n",
        "word2vec_vectors = KeyedVectors.load(\"/content/drive/MyDrive/Colab_Notebooks/dementia/English/dementia/English/Pitt/word2vec_embeddings/word2vec.wordvectors\", mmap='r')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w7iH2eA1Bc1P"
      },
      "outputs": [],
      "source": [
        "# Import libaries\n",
        "import io\n",
        "import re\n",
        "import string\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from gensim.models import Word2Vec\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from xml.etree.ElementTree import parse\n",
        "from xml.etree.ElementTree import fromstring\n",
        "import jieba\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import os\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WqbjVss_QsTd",
        "outputId": "d597bfc7-fafd-4286-9a92-10c8551ad5e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dictionary saved successfully to file\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "aaaa# save dictionary to person_data.pkl file\n",
        "with open('/content/drive/MyDrive/Colab_Notebooks/dementia/English/dementia/English/Pitt/final_combined_data/vocab_dict.pkl', 'wb') as fp:\n",
        "    pickle.dump(vocab, fp)\n",
        "    print('dictionary saved successfully to file')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G5Di86-FQwmI"
      },
      "outputs": [],
      "source": [
        "# Load the vocabulary dictionary\n",
        "import pickle\n",
        "with open('/content/drive/MyDrive/Colab_Notebooks/dementia/English/dementia/English/Pitt/final_combined_data_original/vocab_dict.pkl', 'rb') as handle:\n",
        "    data = handle.read()\n",
        "vocab = pickle.loads(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177
        },
        "id": "j-VJbgFI_nea",
        "outputId": "e7156cd5-d04f-490c-86ba-299dc4fbf0a2"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-8d58bba8612d>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'tokenizer' is not defined"
          ]
        }
      ],
      "source": [
        "vocab = tokenizer.word_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s5tZLP2y_qLg"
      },
      "outputs": [],
      "source": [
        "# Obtain the word embeddings for each word \n",
        "from gensim.models.keyedvectors import Word2VecKeyedVectors\n",
        "import numpy as np\n",
        "def get_weight_matrix():\n",
        "    # define weight matrix dimensions with all 0\n",
        "    weight_matrix = np.zeros((len(vocab)+1, word2vec_vectors.vector_size))\n",
        "    i=0\n",
        "    for key in vocab.keys():\n",
        "      if key=='OOV':\n",
        "        continue\n",
        "      elif key not in word2vec_vectors:\n",
        "        i=i+1\n",
        "        continue\n",
        "      else:\n",
        "        weight_matrix[i + 1] = word2vec_vectors[key]\n",
        "        i=i+1\n",
        "    return weight_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lHzI8AqO_wRo"
      },
      "outputs": [],
      "source": [
        "embedding_vectors = get_weight_matrix()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ayTKfHfNBPjp"
      },
      "outputs": [],
      "source": [
        "from keras.layers import Dense, Flatten, LSTM, Conv1D, MaxPooling1D, Dropout, Activation, Embedding, Input, TimeDistributed, GlobalAveragePooling2D, ConvLSTM2D, Reshape, Concatenate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "toHU9bPN35Ed"
      },
      "outputs": [],
      "source": [
        "# Create the embedding layer\n",
        "embedding_layer = Embedding(input_dim=len(vocab) + 1,\n",
        "                                output_dim=300,\n",
        "                                weights=[embedding_vectors],\n",
        "                                input_length=50,\n",
        "                                trainable=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kE0dd91-LTZD"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZzmSmXXJsYr",
        "outputId": "e5569cef-4474-4c9a-fdda-f0ea95b89333"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers==4.28.0 in /usr/local/lib/python3.10/dist-packages (4.28.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0) (3.12.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0) (0.16.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0) (2.31.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0) (0.13.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0) (4.66.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.28.0) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.28.0) (4.7.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.28.0) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.28.0) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.28.0) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.28.0) (2023.7.22)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers==4.28.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QbHnk_WAzbVT",
        "outputId": "314dd2d4-71cb-48dc-cc85-90e492cecb9e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers==4.28.0 in /usr/local/lib/python3.10/dist-packages (4.28.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0) (3.12.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0) (0.16.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0) (2.31.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0) (0.13.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0) (4.66.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.28.0) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.28.0) (4.7.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.28.0) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.28.0) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.28.0) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.28.0) (2023.7.22)\n",
            "Collecting datasets==2.12.0\n",
            "  Downloading datasets-2.12.0-py3-none-any.whl (474 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m474.6/474.6 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets==2.12.0) (1.23.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.12.0) (9.0.0)\n",
            "Collecting dill<0.3.7,>=0.3.0 (from datasets==2.12.0)\n",
            "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets==2.12.0) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.12.0) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets==2.12.0) (4.66.1)\n",
            "Collecting xxhash (from datasets==2.12.0)\n",
            "  Downloading xxhash-3.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets==2.12.0)\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets==2.12.0) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets==2.12.0) (3.8.5)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.12.0) (0.16.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets==2.12.0) (23.1)\n",
            "Collecting responses<0.19 (from datasets==2.12.0)\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets==2.12.0) (6.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.12.0) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.12.0) (3.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.12.0) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.12.0) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.12.0) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.12.0) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.12.0) (1.3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets==2.12.0) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets==2.12.0) (4.7.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets==2.12.0) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets==2.12.0) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets==2.12.0) (2023.7.22)\n",
            "INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting multiprocess (from datasets==2.12.0)\n",
            "  Downloading multiprocess-0.70.14-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==2.12.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==2.12.0) (2023.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets==2.12.0) (1.16.0)\n",
            "Installing collected packages: xxhash, dill, responses, multiprocess, datasets\n",
            "Successfully installed datasets-2.12.0 dill-0.3.6 multiprocess-0.70.14 responses-0.18.0 xxhash-3.3.0\n"
          ]
        }
      ],
      "source": [
        "# install packages\n",
        "!pip install transformers==4.28.0\n",
        "from transformers import AutoFeatureExtractor\n",
        "!pip install datasets==2.12.0\n",
        "#evaluate\n",
        "from datasets import load_dataset\n",
        "from datasets import load_from_disk\n",
        "#final_combined_dataset=load_from_disk('/content/drive/MyDrive/Colab_Notebooks/dementia/English/dementia/English/Pitt/final_combined_data')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i3pxkSdJw7ju"
      },
      "outputs": [],
      "source": [
        "# Load the dataset\n",
        "from datasets import load_dataset\n",
        "from datasets import load_from_disk\n",
        "import numpy as np\n",
        "final_combined_dataset=load_from_disk('/content/drive/MyDrive/Colab_Notebooks/dementia/English/dementia/English/Pitt/final_combined_data_original')\n",
        "final_combined_dataset=final_combined_dataset.train_test_split(test_size=0.2)\n",
        "final_trained_dataset=final_combined_dataset['train'].train_test_split(test_size=0.2)\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences# Convert nested lists to numpy arrays\n",
        "word_train = np.asarray(final_trained_dataset['train']['word']).astype(np.float32)\n",
        "time_train = np.asarray(final_trained_dataset['train']['time_stamps']).astype(np.float32)\n",
        "word_val = np.asarray(final_trained_dataset['test']['word']).astype(np.float32)\n",
        "time_val = np.asarray(final_trained_dataset['test']['time_stamps']).astype(np.float32)\n",
        "y_train=np.asarray(final_trained_dataset['train']['label']).astype(np.float32)\n",
        "y_val=np.asarray(final_trained_dataset['test']['label']).astype(np.float32)\n",
        "word_test=np.asarray(final_combined_dataset['test']['word']).astype(np.float32)\n",
        "time_test=np.asarray(final_combined_dataset['test']['time_stamps']).astype(np.float32)\n",
        "y_test=np.asarray(final_combined_dataset['test']['label']).astype(np.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v7YMzOpu-xXd",
        "outputId": "fad2f7cc-9978-4390-bd97-de49104aae2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 50)]         0           []                               \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, 50, 300)      522600      ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, 50, 2)]      0           []                               \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 50, 302)      0           ['embedding[0][0]',              \n",
            "                                                                  'input_2[0][0]']                \n",
            "                                                                                                  \n",
            " lstm (LSTM)                    (None, 16)           20416       ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 1)            17          ['lstm[0][0]']                   \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 543,033\n",
            "Trainable params: 20,433\n",
            "Non-trainable params: 522,600\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Build the text and time model\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Embedding, Concatenate, Reshape, LSTM, Dense\n",
        "\n",
        "# Define input layers\n",
        "word_input = Input(shape=(50))\n",
        "time_stamps = Input(shape=(50, 2))\n",
        "\n",
        "# Define embedding layer\n",
        "\n",
        "# Embed word and pos inputs\n",
        "word_embedded = embedding_layer(word_input)\n",
        "\n",
        "# Concatenate word and pos embeddings\n",
        "concatenated = Concatenate()([word_embedded, time_stamps])\n",
        "\n",
        "# Reshape the concatenated tensor\n",
        "#reshaped = Reshape((-1, 16))(concatenated)\n",
        "\n",
        "# Apply LSTM layer\n",
        "lstm_output = LSTM(16, dropout=0.2, recurrent_dropout=0.2)(concatenated)\n",
        "\n",
        "# Apply dense layer for binary classification\n",
        "output = Dense(1, activation='sigmoid')(lstm_output)\n",
        "\n",
        "# Define the model\n",
        "model = Model(inputs=[word_input, time_stamps], outputs=output)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy', tf.keras.metrics.Precision(),tf.keras.metrics.Recall(), tf.keras.metrics.AUC()])\n",
        "\n",
        "# Print the model summary\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xje0RbnzVQot",
        "outputId": "c87ef17f-942a-45f4-f35d-7a899d6cb289"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "378/378 [==============================] - 57s 123ms/step - loss: 0.6457 - accuracy: 0.6012 - precision: 0.5196 - recall: 0.3217 - auc: 0.6223 - val_loss: 0.6001 - val_accuracy: 0.6283 - val_precision: 0.5428 - val_recall: 0.6298 - val_auc: 0.6813\n",
            "Epoch 2/50\n",
            "378/378 [==============================] - 34s 91ms/step - loss: 0.6010 - accuracy: 0.6417 - precision: 0.5431 - recall: 0.7782 - auc: 0.6882 - val_loss: 0.6218 - val_accuracy: 0.6369 - val_precision: 0.5452 - val_recall: 0.7244 - val_auc: 0.6844\n",
            "Epoch 3/50\n",
            "378/378 [==============================] - 35s 93ms/step - loss: 0.5913 - accuracy: 0.6352 - precision: 0.5351 - recall: 0.8195 - auc: 0.6906 - val_loss: 0.5931 - val_accuracy: 0.6336 - val_precision: 0.5440 - val_recall: 0.6939 - val_auc: 0.6855\n",
            "Epoch 4/50\n",
            "378/378 [==============================] - 35s 94ms/step - loss: 0.5846 - accuracy: 0.6306 - precision: 0.5327 - recall: 0.7851 - auc: 0.6908 - val_loss: 0.6026 - val_accuracy: 0.6475 - val_precision: 0.5552 - val_recall: 0.7340 - val_auc: 0.6959\n",
            "Epoch 5/50\n",
            "378/378 [==============================] - 36s 96ms/step - loss: 0.5834 - accuracy: 0.6374 - precision: 0.5370 - recall: 0.8191 - auc: 0.6992 - val_loss: 0.5910 - val_accuracy: 0.6157 - val_precision: 0.5193 - val_recall: 0.9279 - val_auc: 0.6919\n",
            "Epoch 6/50\n",
            "378/378 [==============================] - 35s 93ms/step - loss: 0.5788 - accuracy: 0.6405 - precision: 0.5395 - recall: 0.8244 - auc: 0.6956 - val_loss: 0.5985 - val_accuracy: 0.6323 - val_precision: 0.5464 - val_recall: 0.6410 - val_auc: 0.6970\n",
            "Epoch 7/50\n",
            "378/378 [==============================] - 35s 92ms/step - loss: 0.5754 - accuracy: 0.6463 - precision: 0.5492 - recall: 0.7523 - auc: 0.7118 - val_loss: 0.5836 - val_accuracy: 0.6349 - val_precision: 0.5365 - val_recall: 0.8478 - val_auc: 0.7107\n",
            "Epoch 8/50\n",
            "378/378 [==============================] - 34s 90ms/step - loss: 0.5726 - accuracy: 0.6557 - precision: 0.5530 - recall: 0.8240 - auc: 0.7119 - val_loss: 0.5820 - val_accuracy: 0.6336 - val_precision: 0.5331 - val_recall: 0.9022 - val_auc: 0.7204\n",
            "Epoch 9/50\n",
            "378/378 [==============================] - 34s 91ms/step - loss: 0.5717 - accuracy: 0.6576 - precision: 0.5557 - recall: 0.8094 - auc: 0.7225 - val_loss: 0.5846 - val_accuracy: 0.6475 - val_precision: 0.5528 - val_recall: 0.7628 - val_auc: 0.7297\n",
            "Epoch 10/50\n",
            "378/378 [==============================] - 33s 88ms/step - loss: 0.5688 - accuracy: 0.6612 - precision: 0.5587 - recall: 0.8151 - auc: 0.7255 - val_loss: 0.5940 - val_accuracy: 0.6495 - val_precision: 0.5748 - val_recall: 0.5785 - val_auc: 0.7319\n",
            "Epoch 11/50\n",
            "378/378 [==============================] - 34s 89ms/step - loss: 0.5610 - accuracy: 0.6766 - precision: 0.5810 - recall: 0.7491 - auc: 0.7410 - val_loss: 0.5782 - val_accuracy: 0.6587 - val_precision: 0.5621 - val_recall: 0.7837 - val_auc: 0.7412\n",
            "Epoch 12/50\n",
            "378/378 [==============================] - 34s 91ms/step - loss: 0.5565 - accuracy: 0.6865 - precision: 0.5931 - recall: 0.7422 - auc: 0.7527 - val_loss: 0.5897 - val_accuracy: 0.6872 - val_precision: 0.6256 - val_recall: 0.6026 - val_auc: 0.7456\n",
            "Epoch 13/50\n",
            "378/378 [==============================] - 42s 111ms/step - loss: 0.5525 - accuracy: 0.7049 - precision: 0.6113 - recall: 0.7633 - auc: 0.7630 - val_loss: 0.5803 - val_accuracy: 0.6508 - val_precision: 0.5537 - val_recall: 0.7933 - val_auc: 0.7518\n",
            "Epoch 14/50\n",
            "378/378 [==============================] - 36s 96ms/step - loss: 0.5471 - accuracy: 0.6951 - precision: 0.6091 - recall: 0.7094 - auc: 0.7674 - val_loss: 0.5757 - val_accuracy: 0.6918 - val_precision: 0.6344 - val_recall: 0.5978 - val_auc: 0.7510\n",
            "Epoch 15/50\n",
            "378/378 [==============================] - 33s 88ms/step - loss: 0.5418 - accuracy: 0.7085 - precision: 0.6267 - recall: 0.7094 - auc: 0.7771 - val_loss: 0.5680 - val_accuracy: 0.6898 - val_precision: 0.6169 - val_recall: 0.6554 - val_auc: 0.7580\n",
            "Epoch 16/50\n",
            "378/378 [==============================] - 34s 89ms/step - loss: 0.5405 - accuracy: 0.7069 - precision: 0.6265 - recall: 0.7005 - auc: 0.7764 - val_loss: 0.5834 - val_accuracy: 0.6786 - val_precision: 0.5956 - val_recall: 0.6891 - val_auc: 0.7539\n",
            "Epoch 17/50\n",
            "378/378 [==============================] - 34s 90ms/step - loss: 0.5326 - accuracy: 0.7158 - precision: 0.6343 - recall: 0.7195 - auc: 0.7871 - val_loss: 0.5797 - val_accuracy: 0.6898 - val_precision: 0.6176 - val_recall: 0.6522 - val_auc: 0.7593\n",
            "Epoch 18/50\n",
            "378/378 [==============================] - 35s 93ms/step - loss: 0.5298 - accuracy: 0.7184 - precision: 0.6375 - recall: 0.7216 - auc: 0.7884 - val_loss: 0.5932 - val_accuracy: 0.6892 - val_precision: 0.6271 - val_recall: 0.6090 - val_auc: 0.7578\n",
            "Epoch 19/50\n",
            "378/378 [==============================] - 35s 93ms/step - loss: 0.5244 - accuracy: 0.7277 - precision: 0.6549 - recall: 0.7058 - auc: 0.7978 - val_loss: 0.5654 - val_accuracy: 0.6958 - val_precision: 0.6262 - val_recall: 0.6522 - val_auc: 0.7633\n",
            "Epoch 20/50\n",
            "378/378 [==============================] - 35s 92ms/step - loss: 0.5186 - accuracy: 0.7302 - precision: 0.6589 - recall: 0.7050 - auc: 0.8019 - val_loss: 0.5757 - val_accuracy: 0.6759 - val_precision: 0.5903 - val_recall: 0.7019 - val_auc: 0.7598\n",
            "Epoch 21/50\n",
            "378/378 [==============================] - 35s 92ms/step - loss: 0.5204 - accuracy: 0.7251 - precision: 0.6601 - recall: 0.6750 - auc: 0.8042 - val_loss: 0.5706 - val_accuracy: 0.6766 - val_precision: 0.6744 - val_recall: 0.4183 - val_auc: 0.7596\n",
            "Epoch 22/50\n",
            "378/378 [==============================] - 35s 92ms/step - loss: 0.5180 - accuracy: 0.7340 - precision: 0.6697 - recall: 0.6892 - auc: 0.8064 - val_loss: 0.5695 - val_accuracy: 0.6812 - val_precision: 0.5922 - val_recall: 0.7308 - val_auc: 0.7662\n",
            "Epoch 23/50\n",
            "378/378 [==============================] - 34s 90ms/step - loss: 0.5056 - accuracy: 0.7373 - precision: 0.6733 - recall: 0.6941 - auc: 0.8152 - val_loss: 0.6055 - val_accuracy: 0.7024 - val_precision: 0.6521 - val_recall: 0.5978 - val_auc: 0.7653\n",
            "Epoch 24/50\n",
            "378/378 [==============================] - 34s 90ms/step - loss: 0.5043 - accuracy: 0.7429 - precision: 0.6779 - recall: 0.7070 - auc: 0.8179 - val_loss: 0.5761 - val_accuracy: 0.6971 - val_precision: 0.6199 - val_recall: 0.6875 - val_auc: 0.7672\n",
            "Epoch 25/50\n",
            "378/378 [==============================] - 35s 91ms/step - loss: 0.4984 - accuracy: 0.7532 - precision: 0.6872 - recall: 0.7272 - auc: 0.8243 - val_loss: 0.5794 - val_accuracy: 0.7044 - val_precision: 0.6434 - val_recall: 0.6362 - val_auc: 0.7645\n",
            "Epoch 26/50\n",
            "378/378 [==============================] - 34s 91ms/step - loss: 0.4977 - accuracy: 0.7476 - precision: 0.6817 - recall: 0.7175 - auc: 0.8245 - val_loss: 0.5856 - val_accuracy: 0.6971 - val_precision: 0.6493 - val_recall: 0.5785 - val_auc: 0.7618\n",
            "Epoch 27/50\n",
            "378/378 [==============================] - 39s 103ms/step - loss: 0.4897 - accuracy: 0.7532 - precision: 0.6926 - recall: 0.7123 - auc: 0.8323 - val_loss: 0.6007 - val_accuracy: 0.6706 - val_precision: 0.5724 - val_recall: 0.7981 - val_auc: 0.7674\n",
            "Epoch 28/50\n",
            "378/378 [==============================] - 38s 101ms/step - loss: 0.4880 - accuracy: 0.7580 - precision: 0.7057 - recall: 0.6997 - auc: 0.8327 - val_loss: 0.5750 - val_accuracy: 0.7030 - val_precision: 0.6617 - val_recall: 0.5737 - val_auc: 0.7636\n",
            "Epoch 29/50\n",
            "378/378 [==============================] - 38s 100ms/step - loss: 0.4837 - accuracy: 0.7608 - precision: 0.7152 - recall: 0.6892 - auc: 0.8358 - val_loss: 0.5801 - val_accuracy: 0.6918 - val_precision: 0.6094 - val_recall: 0.7051 - val_auc: 0.7669\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7cef36d3dcf0>"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Train the model\n",
        "import tensorflow as tf\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', restore_best_weights=True, patience=10)\n",
        "model.fit([word_train, time_train], y_train, shuffle =True, validation_data=([word_val, time_val], y_val), epochs=50, batch_size=16, callbacks=[callback])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I-cskhVty8QY",
        "outputId": "c08e3146-66ec-4048-9cc0-94c81adc6475"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "60/60 [==============================] - 1s 16ms/step - loss: 0.5644 - accuracy: 0.6815 - precision: 0.6081 - recall: 0.6362 - auc: 0.7641\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.5643900036811829,\n",
              " 0.6814814805984497,\n",
              " 0.6081081032752991,\n",
              " 0.6362468004226685,\n",
              " 0.7641475200653076]"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Evaluate the model using the test set\n",
        "model.evaluate([word_test, time_test], y_test)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
