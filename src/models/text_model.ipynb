{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fEnPcJaZJlZC"
      },
      "outputs": [],
      "source": [
        "from keras.layers import Dense, Flatten, LSTM, Conv1D, MaxPooling1D, Dropout, Activation, Embedding, Input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9A4UxIZk17i2"
      },
      "outputs": [],
      "source": [
        "from gensim.models import KeyedVectors\n",
        "word2vec_vectors = KeyedVectors.load(\"/content/drive/MyDrive/Colab_Notebooks/dementia/English/dementia/English/Pitt/word2vec_embeddings/word2vec.wordvectors\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ccx0al860AKj"
      },
      "outputs": [],
      "source": [
        "vocab = tokenizer.word_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uG9k8n8T_9vn"
      },
      "outputs": [],
      "source": [
        "embedding_vectors = get_weight_matrix()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5cBfCFJyIhLm"
      },
      "outputs": [],
      "source": [
        "embedding_layer = Embedding(input_dim=len(vocab) + 1,\n",
        "                                output_dim=300,\n",
        "                                weights=[embedding_vectors],\n",
        "                                input_length=50,\n",
        "                                trainable=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GoA1W4JEJ-j_"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pOh00CAlEnmu",
        "outputId": "c225735d-8efb-4440-ed1f-6a614e94cbce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 50)]              0         \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 50, 300)           522600    \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 16)                20288     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 542,905\n",
            "Trainable params: 20,305\n",
            "Non-trainable params: 522,600\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import Model\n",
        "#from tensorflow.keras.layers import Input, Embedding, Concatenate, Reshape, LSTM, Dense\n",
        "# Define input layers\n",
        "word_input = Input(shape=(50))\n",
        "\n",
        "# Define embedding layer\n",
        "\n",
        "# Embed word and pos inputs\n",
        "word_embedded = embedding_layer(word_input)\n",
        "\n",
        "# Concatenate word and pos embeddings\n",
        "\n",
        "# Reshape the concatenated tensor\n",
        "#reshaped = Reshape((-1, 16))(concatenated)\n",
        "\n",
        "# Apply LSTM layer\n",
        "lstm_output = LSTM(16, dropout=0.2, recurrent_dropout=0.2)(word_embedded)\n",
        "\n",
        "# Apply dense layer for binary classification\n",
        "output = Dense(1, activation='sigmoid')(lstm_output)\n",
        "\n",
        "#opt = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
        "# Define the model\n",
        "model0 = Model(inputs=word_input, outputs=output)\n",
        "\n",
        "# Compile the model\n",
        "model0.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', tf.keras.metrics.Precision(),tf.keras.metrics.Recall(), tf.keras.metrics.AUC()])\n",
        "\n",
        "# Print the model summary\n",
        "model0.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3kqaw4iQt0RO",
        "outputId": "4ad8642e-99cd-4907-8f30-453b4a4fc5e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "378/378 [==============================] - 38s 87ms/step - loss: 0.6428 - accuracy: 0.6263 - precision: 0.5538 - recall: 0.3816 - auc: 0.6432 - val_loss: 0.6902 - val_accuracy: 0.6151 - val_precision: 0.5491 - val_recall: 0.5457 - val_auc: 0.6557\n",
            "Epoch 2/50\n",
            "378/378 [==============================] - 31s 83ms/step - loss: 0.6085 - accuracy: 0.6478 - precision: 0.5486 - recall: 0.7197 - auc: 0.6952 - val_loss: 0.6167 - val_accuracy: 0.5827 - val_precision: 0.5432 - val_recall: 0.1364 - val_auc: 0.6815\n",
            "Epoch 3/50\n",
            "378/378 [==============================] - 33s 88ms/step - loss: 0.5908 - accuracy: 0.6442 - precision: 0.5444 - recall: 0.7254 - auc: 0.6956 - val_loss: 0.6033 - val_accuracy: 0.6197 - val_precision: 0.5343 - val_recall: 0.8450 - val_auc: 0.6851\n",
            "Epoch 4/50\n",
            "378/378 [==============================] - 32s 86ms/step - loss: 0.5768 - accuracy: 0.6627 - precision: 0.5577 - recall: 0.7939 - auc: 0.7224 - val_loss: 0.6288 - val_accuracy: 0.6323 - val_precision: 0.6005 - val_recall: 0.4124 - val_auc: 0.7008\n",
            "Epoch 5/50\n",
            "378/378 [==============================] - 32s 84ms/step - loss: 0.5689 - accuracy: 0.6701 - precision: 0.5668 - recall: 0.7758 - auc: 0.7319 - val_loss: 0.6013 - val_accuracy: 0.6257 - val_precision: 0.5392 - val_recall: 0.8419 - val_auc: 0.7076\n",
            "Epoch 6/50\n",
            "378/378 [==============================] - 29s 78ms/step - loss: 0.5664 - accuracy: 0.6786 - precision: 0.5767 - recall: 0.7656 - auc: 0.7430 - val_loss: 0.5969 - val_accuracy: 0.6508 - val_precision: 0.5769 - val_recall: 0.6806 - val_auc: 0.7150\n",
            "Epoch 7/50\n",
            "378/378 [==============================] - 33s 88ms/step - loss: 0.5612 - accuracy: 0.6878 - precision: 0.5962 - recall: 0.7025 - auc: 0.7515 - val_loss: 0.6117 - val_accuracy: 0.6422 - val_precision: 0.5535 - val_recall: 0.8341 - val_auc: 0.7210\n",
            "Epoch 8/50\n",
            "378/378 [==============================] - 37s 99ms/step - loss: 0.5538 - accuracy: 0.6943 - precision: 0.6003 - recall: 0.7262 - auc: 0.7590 - val_loss: 0.5939 - val_accuracy: 0.6488 - val_precision: 0.6105 - val_recall: 0.4884 - val_auc: 0.7215\n",
            "Epoch 9/50\n",
            "378/378 [==============================] - 32s 85ms/step - loss: 0.5508 - accuracy: 0.7021 - precision: 0.6148 - recall: 0.7012 - auc: 0.7663 - val_loss: 0.5917 - val_accuracy: 0.6574 - val_precision: 0.5981 - val_recall: 0.6000 - val_auc: 0.7220\n",
            "Epoch 10/50\n",
            "378/378 [==============================] - 30s 80ms/step - loss: 0.5456 - accuracy: 0.7041 - precision: 0.6223 - recall: 0.6787 - auc: 0.7710 - val_loss: 0.6056 - val_accuracy: 0.6528 - val_precision: 0.5698 - val_recall: 0.7597 - val_auc: 0.7305\n",
            "Epoch 11/50\n",
            "378/378 [==============================] - 30s 80ms/step - loss: 0.5387 - accuracy: 0.7146 - precision: 0.6404 - recall: 0.6684 - auc: 0.7815 - val_loss: 0.5948 - val_accuracy: 0.6561 - val_precision: 0.6106 - val_recall: 0.5349 - val_auc: 0.7344\n",
            "Epoch 12/50\n",
            "378/378 [==============================] - 32s 86ms/step - loss: 0.5340 - accuracy: 0.7103 - precision: 0.6394 - recall: 0.6475 - auc: 0.7881 - val_loss: 0.5927 - val_accuracy: 0.6548 - val_precision: 0.5839 - val_recall: 0.6636 - val_auc: 0.7340\n",
            "Epoch 13/50\n",
            "378/378 [==============================] - 32s 85ms/step - loss: 0.5307 - accuracy: 0.7226 - precision: 0.6470 - recall: 0.6881 - auc: 0.7920 - val_loss: 0.6039 - val_accuracy: 0.6667 - val_precision: 0.6396 - val_recall: 0.5008 - val_auc: 0.7373\n",
            "Epoch 14/50\n",
            "378/378 [==============================] - 31s 81ms/step - loss: 0.5261 - accuracy: 0.7234 - precision: 0.6595 - recall: 0.6508 - auc: 0.7977 - val_loss: 0.6330 - val_accuracy: 0.6607 - val_precision: 0.6054 - val_recall: 0.5876 - val_auc: 0.7280\n",
            "Epoch 15/50\n",
            "378/378 [==============================] - 31s 81ms/step - loss: 0.5229 - accuracy: 0.7203 - precision: 0.6589 - recall: 0.6365 - auc: 0.8003 - val_loss: 0.5903 - val_accuracy: 0.6422 - val_precision: 0.6912 - val_recall: 0.2915 - val_auc: 0.7443\n",
            "Epoch 16/50\n",
            "378/378 [==============================] - 32s 86ms/step - loss: 0.5210 - accuracy: 0.7289 - precision: 0.6718 - recall: 0.6418 - auc: 0.8030 - val_loss: 0.5916 - val_accuracy: 0.6667 - val_precision: 0.6353 - val_recall: 0.5132 - val_auc: 0.7442\n",
            "Epoch 17/50\n",
            "378/378 [==============================] - 33s 86ms/step - loss: 0.5160 - accuracy: 0.7322 - precision: 0.6746 - recall: 0.6500 - auc: 0.8069 - val_loss: 0.5919 - val_accuracy: 0.6706 - val_precision: 0.5823 - val_recall: 0.8062 - val_auc: 0.7474\n",
            "Epoch 18/50\n",
            "378/378 [==============================] - 31s 83ms/step - loss: 0.5157 - accuracy: 0.7348 - precision: 0.6744 - recall: 0.6631 - auc: 0.8071 - val_loss: 0.5931 - val_accuracy: 0.6812 - val_precision: 0.6304 - val_recall: 0.6109 - val_auc: 0.7524\n",
            "Epoch 19/50\n",
            "378/378 [==============================] - 29s 78ms/step - loss: 0.5091 - accuracy: 0.7380 - precision: 0.6837 - recall: 0.6529 - auc: 0.8138 - val_loss: 0.5803 - val_accuracy: 0.6753 - val_precision: 0.6481 - val_recall: 0.5225 - val_auc: 0.7495\n",
            "Epoch 20/50\n",
            "378/378 [==============================] - 32s 86ms/step - loss: 0.5042 - accuracy: 0.7479 - precision: 0.6976 - recall: 0.6627 - auc: 0.8203 - val_loss: 0.5945 - val_accuracy: 0.6872 - val_precision: 0.6498 - val_recall: 0.5783 - val_auc: 0.7515\n",
            "Epoch 21/50\n",
            "378/378 [==============================] - 33s 86ms/step - loss: 0.5000 - accuracy: 0.7504 - precision: 0.6936 - recall: 0.6836 - auc: 0.8245 - val_loss: 0.5984 - val_accuracy: 0.6825 - val_precision: 0.6471 - val_recall: 0.5628 - val_auc: 0.7499\n",
            "Epoch 22/50\n",
            "378/378 [==============================] - 32s 84ms/step - loss: 0.4988 - accuracy: 0.7479 - precision: 0.6957 - recall: 0.6672 - auc: 0.8226 - val_loss: 0.5968 - val_accuracy: 0.6878 - val_precision: 0.6293 - val_recall: 0.6527 - val_auc: 0.7543\n",
            "Epoch 23/50\n",
            "378/378 [==============================] - 30s 78ms/step - loss: 0.4960 - accuracy: 0.7543 - precision: 0.7009 - recall: 0.6828 - auc: 0.8269 - val_loss: 0.5877 - val_accuracy: 0.6706 - val_precision: 0.6738 - val_recall: 0.4419 - val_auc: 0.7519\n",
            "Epoch 24/50\n",
            "378/378 [==============================] - 32s 86ms/step - loss: 0.4904 - accuracy: 0.7525 - precision: 0.7050 - recall: 0.6652 - auc: 0.8318 - val_loss: 0.6055 - val_accuracy: 0.6865 - val_precision: 0.6492 - val_recall: 0.5767 - val_auc: 0.7537\n",
            "Epoch 25/50\n",
            "378/378 [==============================] - 33s 87ms/step - loss: 0.4882 - accuracy: 0.7540 - precision: 0.6957 - recall: 0.6943 - auc: 0.8338 - val_loss: 0.6338 - val_accuracy: 0.6667 - val_precision: 0.6822 - val_recall: 0.4093 - val_auc: 0.7499\n",
            "Epoch 26/50\n",
            "378/378 [==============================] - 33s 86ms/step - loss: 0.4825 - accuracy: 0.7628 - precision: 0.7103 - recall: 0.6963 - auc: 0.8391 - val_loss: 0.5716 - val_accuracy: 0.6931 - val_precision: 0.6313 - val_recall: 0.6744 - val_auc: 0.7591\n",
            "Epoch 27/50\n",
            "378/378 [==============================] - 33s 86ms/step - loss: 0.4832 - accuracy: 0.7618 - precision: 0.7139 - recall: 0.6840 - auc: 0.8375 - val_loss: 0.5901 - val_accuracy: 0.6839 - val_precision: 0.6307 - val_recall: 0.6248 - val_auc: 0.7552\n",
            "Epoch 28/50\n",
            "378/378 [==============================] - 31s 81ms/step - loss: 0.4834 - accuracy: 0.7672 - precision: 0.7158 - recall: 0.7020 - auc: 0.8379 - val_loss: 0.6171 - val_accuracy: 0.6726 - val_precision: 0.6630 - val_recall: 0.4729 - val_auc: 0.7533\n",
            "Epoch 29/50\n",
            "378/378 [==============================] - 32s 86ms/step - loss: 0.4751 - accuracy: 0.7664 - precision: 0.7172 - recall: 0.6955 - auc: 0.8441 - val_loss: 0.5917 - val_accuracy: 0.6931 - val_precision: 0.6394 - val_recall: 0.6434 - val_auc: 0.7533\n",
            "Epoch 30/50\n",
            "378/378 [==============================] - 33s 88ms/step - loss: 0.4682 - accuracy: 0.7747 - precision: 0.7311 - recall: 0.6988 - auc: 0.8505 - val_loss: 0.6558 - val_accuracy: 0.6660 - val_precision: 0.6636 - val_recall: 0.4403 - val_auc: 0.7480\n",
            "Epoch 31/50\n",
            "378/378 [==============================] - 30s 79ms/step - loss: 0.4674 - accuracy: 0.7687 - precision: 0.7253 - recall: 0.6873 - auc: 0.8510 - val_loss: 0.5811 - val_accuracy: 0.6845 - val_precision: 0.6687 - val_recall: 0.5163 - val_auc: 0.7554\n",
            "Epoch 32/50\n",
            "378/378 [==============================] - 31s 83ms/step - loss: 0.4631 - accuracy: 0.7773 - precision: 0.7374 - recall: 0.6963 - auc: 0.8529 - val_loss: 0.6233 - val_accuracy: 0.6779 - val_precision: 0.6574 - val_recall: 0.5116 - val_auc: 0.7476\n",
            "Epoch 33/50\n",
            "378/378 [==============================] - 32s 85ms/step - loss: 0.4635 - accuracy: 0.7729 - precision: 0.7426 - recall: 0.6693 - auc: 0.8534 - val_loss: 0.6168 - val_accuracy: 0.6825 - val_precision: 0.6627 - val_recall: 0.5209 - val_auc: 0.7433\n",
            "Epoch 34/50\n",
            "378/378 [==============================] - 33s 88ms/step - loss: 0.4577 - accuracy: 0.7831 - precision: 0.7413 - recall: 0.7107 - auc: 0.8591 - val_loss: 0.6265 - val_accuracy: 0.6792 - val_precision: 0.6521 - val_recall: 0.5318 - val_auc: 0.7458\n",
            "Epoch 35/50\n",
            "378/378 [==============================] - 31s 83ms/step - loss: 0.4592 - accuracy: 0.7749 - precision: 0.7353 - recall: 0.6910 - auc: 0.8563 - val_loss: 0.6125 - val_accuracy: 0.6779 - val_precision: 0.6632 - val_recall: 0.4977 - val_auc: 0.7433\n",
            "Epoch 36/50\n",
            "378/378 [==============================] - 30s 78ms/step - loss: 0.4518 - accuracy: 0.7838 - precision: 0.7481 - recall: 0.7000 - auc: 0.8620 - val_loss: 0.6354 - val_accuracy: 0.6832 - val_precision: 0.6235 - val_recall: 0.6496 - val_auc: 0.7414\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x79480bb967a0>"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', restore_best_weights=True, patience=10)\n",
        "model0.fit(word_train, y_train, shuffle =True, validation_data=(word_val, y_val), epochs=50, batch_size=16, callbacks=[callback])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U7MfhTg4FAgu",
        "outputId": "270d8a9f-1c50-4034-ea2d-1f42be98d667"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "60/60 [==============================] - 1s 20ms/step - loss: 0.5588 - accuracy: 0.6995 - precision: 0.6310 - recall: 0.6726 - auc: 0.7716\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.5587708353996277,\n",
              " 0.6994708776473999,\n",
              " 0.6309523582458496,\n",
              " 0.6725888252258301,\n",
              " 0.7716495990753174]"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model0.evaluate(word_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "unz_C2mJIwuG"
      },
      "outputs": [],
      "source": [
        "## Fit the model\n",
        "model0.save(\"/content/drive/MyDrive/Colab_Notebooks/dementia/English/Pitt-xml/dementia_lstm_model.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H8aCxP4KIQZh"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "model = tf.keras.models.load_model('/content/drive/MyDrive/Colab_Notebooks/dementia/English/dementia/English/Pitt/trained_models_shorts_augmented/word')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
